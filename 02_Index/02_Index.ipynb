{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bc1149",
   "metadata": {},
   "source": [
    "## Index Tutorial for NYC Neighborhood Tabulation Areas\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danmillr/places-platforms/blob/main/02_Index/02_Index.ipynb)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview & Learning Objectives\n",
    "This tutorial guides you through constructing a spatial index using real-world data from New York City. We will build a **Heat Vulnerability Index (HVI)** that combines environmental and demographic indicators.\n",
    "\n",
    "You will:\n",
    "- Learn how spatial indices are used for policy and planning\n",
    "- Join multiple spatial and tabular datasets\n",
    "- Normalize variables to prepare them for aggregation\n",
    "- Build a weighted composite index with dynamic inputs\n",
    "- Create static and interactive maps\n",
    "- Critically evaluate the assumptions behind your index\n",
    "\n",
    "By the end, you should be able to construct your own index and reflect on how methodological decisions shape outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Setup\n",
    "Install and import the required libraries. These include pandas and geopandas for data handling, matplotlib and folium for visualization, and ipywidgets for interactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f57cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium import Choropleth\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41844a73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Overview\n",
    "We are using four datasets:\n",
    "1. **NTA GeoJSON** – geographic boundaries for Neighborhood Tabulation Areas\n",
    "2. **Heat Vulnerability Index (HVI)** – a precomputed score reflecting environmental risk factors\n",
    "3. **Household Crowding** – % of households with more than one person per room\n",
    "4. **Canopy/Shade** – a proxy for protection from heat based on tree cover\n",
    "\n",
    "These datasets are at the same spatial level (NTA) or have identifiers (`GEOCODE`) that allow matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_gdf = gpd.read_file(\"https://github.com/danmillr/places-platforms/blob/main/02_Index/Data/2020%20Neighborhood%20Tabulation%20Areas%20(NTAs)_20250626.geojson\")\n",
    "hvi_df = pd.read_csv(\"path_to/hvi-nta-2020.csv\")\n",
    "crowding_df = pd.read_csv(\"https://github.com/danmillr/places-platforms/blob/main/02_Index/Data/nta_crowding.csv\")\n",
    "canopy_df = pd.read_csv(\"https://github.com/danmillr/places-platforms/blob/main/02_Index/Data/canopystreettree_supp_nta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88046df3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Data Linking & Validation\n",
    "This step merges the datasets into one table. The keys used are `NTACode` and `GEOCODE`. Always inspect your joins to ensure you aren't introducing nulls or losing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3263413",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowding_df = crowding_df.rename(columns={\"GeoID\": \"GEOCODE\"})\n",
    "canopy_df[\"NTACode\"] = canopy_df[\"ntacode\"].str.upper()\n",
    "\n",
    "merged_df = hvi_df.merge(crowding_df, on=\"GEOCODE\", how=\"left\")\n",
    "merged_df = merged_df.merge(canopy_df, on=\"NTACode\", how=\"left\")\n",
    "merged_gdf = nta_gdf.merge(merged_df, on=\"NTACode\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbdebd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Exploratory Data Analysis\n",
    "We explore variable distributions to identify skew or outliers. This step also helps students reason about transformations needed before constructing the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf['Percent'].dropna().astype(float).hist(bins=20)\n",
    "plt.title(\"Crowding Rate Distribution\")\n",
    "plt.xlabel(\"Percent Crowded\")\n",
    "plt.ylabel(\"Number of NTAs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd938865",
   "metadata": {},
   "source": [
    "Plotting a map of the raw variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf.plot(column='Percent', cmap='OrRd', legend=True, figsize=(10,6))\n",
    "plt.title(\"Crowding Rate by NTA\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aee6b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Normalization\n",
    "To combine variables, they must be on the same scale. We use **min–max normalization**:\n",
    "\n",
    "\\[ x_{norm} = \f\n",
    "rac{x - x_{min}}{x_{max} - x_{min}} \\]\n",
    "\n",
    "This is useful for visualization and additive indices but sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d76bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Percent', 'SURFACE_TEMP', 'canopy_pct']\n",
    "for var in variables:\n",
    "    merged_gdf[f\"{var}_norm\"] = (\n",
    "        merged_gdf[var] - merged_gdf[var].min()\n",
    "    ) / (merged_gdf[var].max() - merged_gdf[var].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65c1d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Build Your Index (Interactive)\n",
    "You can set your own weights to explore different assumptions about which factors contribute most to heat vulnerability. Note that canopy is inverted to represent less vulnerability with more coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_crowd = widgets.FloatSlider(0.33, 0, 1, 0.01, description='Crowding')\n",
    "w_temp = widgets.FloatSlider(0.33, 0, 1, 0.01, description='Temperature')\n",
    "w_canopy = widgets.FloatSlider(0.33, 0, 1, 0.01, description='Canopy')\n",
    "\n",
    "def update_index(crowd, temp, canopy):\n",
    "    total = crowd + temp + canopy\n",
    "    merged_gdf['custom_index'] = (\n",
    "        crowd * merged_gdf['Percent_norm'] +\n",
    "        temp * merged_gdf['SURFACE_TEMP_norm'] +\n",
    "        canopy * (1 - merged_gdf['canopy_pct_norm'])\n",
    "    ) / total\n",
    "\n",
    "    ax = merged_gdf.plot(\n",
    "        column='custom_index', cmap='plasma', legend=True, figsize=(10,6)\n",
    "    )\n",
    "    plt.title(\"Custom Heat Vulnerability Index\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "widgets.interact(update_index, crowd=w_crowd, temp=w_temp, canopy=w_canopy);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245efcb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Advanced Options\n",
    "Explore advanced methods to improve, validate, or challenge your index construction. These techniques go beyond static weightings and help illuminate structure in your data.\n",
    "\n",
    "**Alternative normalization:** Use z-score normalization to standardize variables based on their distance from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412993db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "merged_gdf['Percent_z'] = zscore(merged_gdf['Percent'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648198ba",
   "metadata": {},
   "source": [
    "This is particularly useful if your variables are skewed or have outliers, as it centers data at zero with a standard deviation of one.\n",
    "\n",
    "**Add more variables:** You can enrich the index by including:\n",
    "- % of residents over 65 (age vulnerability)\n",
    "- % without air conditioning (exposure risk)\n",
    "- % non-English speakers (language isolation)\n",
    "- Access to public cooling centers or shaded green space\n",
    "\n",
    "Make sure to normalize any new variables before combining them.\n",
    "\n",
    "**PCA (Principal Component Analysis):** PCA reduces multiple related variables into components that capture the most variance. It can be used to simplify and weight input dimensions empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['Percent_norm', 'SURFACE_TEMP_norm', 'canopy_pct_norm']\n",
    "X = StandardScaler().fit_transform(merged_gdf[features].dropna())\n",
    "pca = PCA(n_components=1)\n",
    "merged_gdf['pca_index'] = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8f65c",
   "metadata": {},
   "source": [
    "**Clustering:** Use algorithms like KMeans to segment NTAs into distinct groups of vulnerability, rather than using a single continuous index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "merged_gdf['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c71f8",
   "metadata": {},
   "source": [
    "These tools allow you to compare your subjective weightings with data-driven structures. They can help expose hidden patterns or support alternative interpretations of vulnerability.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Export Your Results\n",
    "Export your final output as a GeoJSON to use in GIS or for sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68dcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf[['NTACode', 'custom_index', 'geometry']].to_file(\"custom_hvi.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f979485",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Critical Reflection\n",
    "Questions for consideration:\n",
    "- What kinds of vulnerability are not captured here?\n",
    "- How do your weights reflect your assumptions?\n",
    "- Are there ethical concerns with publicly mapping vulnerability?\n",
    "- What might a participatory or community-informed index look like?\n",
    "\n",
    "Indexes are powerful—but they are never neutral. Be reflective, transparent, and critical."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
